{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a0675ea",
   "metadata": {},
   "source": [
    "# 📍  \n",
    "Using the `fraudTrain.csv` dataset, create models to predict if a transaction is fraudulent or not. After building your model, use it to make predictions on the `fraudTest.csv` dataset. Your goal is not only to make accurate predictions but also to understand how your model makes these decisions. To do this, use Model Interpretability techniques to show which information helps the model decide if a transaction is fraudulent. Your task is to explain your model's decisions in a way that anyone can understand, even without a background in data science.📍 📍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c47e9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.0.3-py3-none-win_amd64.whl (99.8 MB)\n",
      "     ---------------------------------------- 99.8/99.8 MB 7.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy in c:\\users\\jeyan\\anaconda3\\lib\\site-packages (from xgboost) (1.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\jeyan\\anaconda3\\lib\\site-packages (from xgboost) (1.23.5)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d011bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make necessary imports\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import xgboost\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ef63fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in c:\\users\\jeyan\\anaconda3\\lib\\site-packages (0.45.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\jeyan\\anaconda3\\lib\\site-packages (from shap) (1.10.0)\n",
      "Requirement already satisfied: slicer==0.0.7 in c:\\users\\jeyan\\anaconda3\\lib\\site-packages (from shap) (0.0.7)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\jeyan\\anaconda3\\lib\\site-packages (from shap) (2.0.0)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\jeyan\\anaconda3\\lib\\site-packages (from shap) (22.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\jeyan\\anaconda3\\lib\\site-packages (from shap) (1.5.3)\n",
      "Requirement already satisfied: numba in c:\\users\\jeyan\\anaconda3\\lib\\site-packages (from shap) (0.56.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\jeyan\\anaconda3\\lib\\site-packages (from shap) (1.4.1.post1)\n",
      "Requirement already satisfied: numpy in c:\\users\\jeyan\\anaconda3\\lib\\site-packages (from shap) (1.23.5)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\jeyan\\anaconda3\\lib\\site-packages (from shap) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\jeyan\\anaconda3\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jeyan\\anaconda3\\lib\\site-packages (from numba->shap) (65.6.3)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in c:\\users\\jeyan\\anaconda3\\lib\\site-packages (from numba->shap) (0.39.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\jeyan\\anaconda3\\lib\\site-packages (from pandas->shap) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jeyan\\anaconda3\\lib\\site-packages (from pandas->shap) (2022.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\jeyan\\anaconda3\\lib\\site-packages (from scikit-learn->shap) (2.2.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\jeyan\\anaconda3\\lib\\site-packages (from scikit-learn->shap) (1.3.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jeyan\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1892f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "fraud_train = pd.read_csv(\"dataset/fraudTrain.csv\")\n",
    "fraud_test = pd.read_csv(\"dataset/fraudTest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "368ad2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 trans_date_trans_time            cc_num  \\\n",
      "0           0   2019-01-01 00:00:18  2703186189652095   \n",
      "1           1   2019-01-01 00:00:44      630423337322   \n",
      "2           2   2019-01-01 00:00:51    38859492057661   \n",
      "3           3   2019-01-01 00:01:16  3534093764340240   \n",
      "4           4   2019-01-01 00:03:06   375534208663984   \n",
      "\n",
      "                             merchant       category     amt      first  \\\n",
      "0          fraud_Rippin, Kub and Mann       misc_net    4.97   Jennifer   \n",
      "1     fraud_Heller, Gutmann and Zieme    grocery_pos  107.23  Stephanie   \n",
      "2                fraud_Lind-Buckridge  entertainment  220.11     Edward   \n",
      "3  fraud_Kutch, Hermiston and Farrell  gas_transport   45.00     Jeremy   \n",
      "4                 fraud_Keeling-Crist       misc_pos   41.96      Tyler   \n",
      "\n",
      "      last gender                        street  ...      lat      long  \\\n",
      "0    Banks      F                561 Perry Cove  ...  36.0788  -81.1781   \n",
      "1     Gill      F  43039 Riley Greens Suite 393  ...  48.8878 -118.2105   \n",
      "2  Sanchez      M      594 White Dale Suite 530  ...  42.1808 -112.2620   \n",
      "3    White      M   9443 Cynthia Court Apt. 038  ...  46.2306 -112.1138   \n",
      "4   Garcia      M              408 Bradley Rest  ...  38.4207  -79.4629   \n",
      "\n",
      "   city_pop                                job         dob  \\\n",
      "0      3495          Psychologist, counselling  1988-03-09   \n",
      "1       149  Special educational needs teacher  1978-06-21   \n",
      "2      4154        Nature conservation officer  1962-01-19   \n",
      "3      1939                    Patent attorney  1967-01-12   \n",
      "4        99     Dance movement psychotherapist  1986-03-28   \n",
      "\n",
      "                          trans_num   unix_time  merch_lat  merch_long  \\\n",
      "0  0b242abb623afc578575680df30655b9  1325376018  36.011293  -82.048315   \n",
      "1  1f76529f8574734946361c461b024d99  1325376044  49.159047 -118.186462   \n",
      "2  a1a22d70485983eac12b5b88dad1cf95  1325376051  43.150704 -112.154481   \n",
      "3  6b849c168bdad6f867558c3793159a81  1325376076  47.034331 -112.561071   \n",
      "4  a41d7549acf90789359a9aa5346dcb46  1325376186  38.674999  -78.632459   \n",
      "\n",
      "   is_fraud  \n",
      "0         0  \n",
      "1         0  \n",
      "2         0  \n",
      "3         0  \n",
      "4         0  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1296675 entries, 0 to 1296674\n",
      "Data columns (total 23 columns):\n",
      " #   Column                 Non-Null Count    Dtype  \n",
      "---  ------                 --------------    -----  \n",
      " 0   Unnamed: 0             1296675 non-null  int64  \n",
      " 1   trans_date_trans_time  1296675 non-null  object \n",
      " 2   cc_num                 1296675 non-null  int64  \n",
      " 3   merchant               1296675 non-null  object \n",
      " 4   category               1296675 non-null  object \n",
      " 5   amt                    1296675 non-null  float64\n",
      " 6   first                  1296675 non-null  object \n",
      " 7   last                   1296675 non-null  object \n",
      " 8   gender                 1296675 non-null  object \n",
      " 9   street                 1296675 non-null  object \n",
      " 10  city                   1296675 non-null  object \n",
      " 11  state                  1296675 non-null  object \n",
      " 12  zip                    1296675 non-null  int64  \n",
      " 13  lat                    1296675 non-null  float64\n",
      " 14  long                   1296675 non-null  float64\n",
      " 15  city_pop               1296675 non-null  int64  \n",
      " 16  job                    1296675 non-null  object \n",
      " 17  dob                    1296675 non-null  object \n",
      " 18  trans_num              1296675 non-null  object \n",
      " 19  unix_time              1296675 non-null  int64  \n",
      " 20  merch_lat              1296675 non-null  float64\n",
      " 21  merch_long             1296675 non-null  float64\n",
      " 22  is_fraud               1296675 non-null  int64  \n",
      "dtypes: float64(5), int64(6), object(12)\n",
      "memory usage: 227.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Explore the data\n",
    "print(fraud_train.head())\n",
    "print(fraud_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "615d03b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data (handle missing values, categorical encoding, etc.)\n",
    "\n",
    "# Step 2: Model Training\n",
    "# Train various machine learning models (e.g., logistic regression, random forest, XGBoost) on the fraudTrain.csv dataset\n",
    "\n",
    "# Step 3: Model Evaluation\n",
    "# Evaluate the performance of the trained models using appropriate metrics (e.g., accuracy, precision, recall, F1-score, ROC-AUC)\n",
    "\n",
    "# Step 4: Model Interpretability\n",
    "# Use model interpretability techniques to understand how the models make decisions and explain their predictions\n",
    "# Example: Feature Importance Analysis, SHAP (SHapley Additive exPlanations), LIME (Local Interpretable Model-agnostic Explanations)\n",
    "\n",
    "# Step 5: Prediction on Test Data\n",
    "# Use the trained models to make predictions on the fraudTest.csv dataset\n",
    "# Evaluate the performance of the models on the test data\n",
    "\n",
    "# Example code for training a logistic regression model and interpreting its decisions\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "064c0dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "X_train = fraud_train.drop('is_fraud', axis=1)\n",
    "y_train = fraud_train['is_fraud']\n",
    "X_test = fraud_test.drop('is_fraud', axis=1)\n",
    "y_test = fraud_test['is_fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbdb952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train and test data for preprocessing\n",
    "data = pd.concat([fraud_train, fraud_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69981f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1852394 entries, 0 to 1852393\n",
      "Data columns (total 23 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   Unnamed: 0             int64  \n",
      " 1   trans_date_trans_time  object \n",
      " 2   cc_num                 int64  \n",
      " 3   merchant               object \n",
      " 4   category               object \n",
      " 5   amt                    float64\n",
      " 6   first                  object \n",
      " 7   last                   object \n",
      " 8   gender                 object \n",
      " 9   street                 object \n",
      " 10  city                   object \n",
      " 11  state                  object \n",
      " 12  zip                    int64  \n",
      " 13  lat                    float64\n",
      " 14  long                   float64\n",
      " 15  city_pop               int64  \n",
      " 16  job                    object \n",
      " 17  dob                    object \n",
      " 18  trans_num              object \n",
      " 19  unix_time              int64  \n",
      " 20  merch_lat              float64\n",
      " 21  merch_long             float64\n",
      " 22  is_fraud               int64  \n",
      "dtypes: float64(5), int64(6), object(12)\n",
      "memory usage: 325.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d48d1700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "data.drop(columns=[\"Unnamed: 0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c603d211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "# Replace missing values in categorical columns with the mode\n",
    "categorical_cols = data.select_dtypes(include=[\"object\"]).columns\n",
    "for col in categorical_cols:\n",
    "    data[col].fillna(data[col].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee4874e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values in numerical columns with the mean\n",
    "numerical_cols = data.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "data[numerical_cols] = imputer.fit_transform(data[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1c866d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform categorical encoding\n",
    "label_encoder = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    data[col] = label_encoder.fit_transform(data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00dc0d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the preprocessed data back into train and test datasets\n",
    "fraud_train_preprocessed = data.iloc[:fraud_train.shape[0], :]\n",
    "fraud_test_preprocessed = data.iloc[fraud_train.shape[0]:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02e80929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into features and target variables\n",
    "X_train = fraud_train_preprocessed.drop(columns=[\"is_fraud\"])\n",
    "y_train = fraud_train_preprocessed[\"is_fraud\"]\n",
    "X_test = fraud_test_preprocessed.drop(columns=[\"is_fraud\"])\n",
    "y_test = fraud_test_preprocessed[\"is_fraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97723da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further splitting for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca77c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic regression model\n",
    "logistic_regression_model = LogisticRegression()\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "# Train random forest model\n",
    "random_forest_model = RandomForestClassifier()\n",
    "random_forest_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c65ae3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost model\n",
    "xgboost_model = XGBClassifier()\n",
    "xgboost_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce81f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to evaluate the models\n",
    "def evaluate_model(model, X_val, y_val):\n",
    "    y_pred = model.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    roc_auc = roc_auc_score(y_val, y_pred_proba[:, 1])\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# Evaluate logistic regression model\n",
    "print(\"Logistic Regression Model:\")\n",
    "evaluate_model(logistic_regression_model, X_val, y_val)\n",
    "print()\n",
    "\n",
    "# Evaluate random forest model\n",
    "print(\"Random Forest Model:\")\n",
    "evaluate_model(random_forest_model, X_val, y_val)\n",
    "print()\n",
    "\n",
    "# Evaluate XGBoost model\n",
    "print(\"XGBoost Model:\")\n",
    "evaluate_model(xgboost_model, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2059a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "from sklearn.inspection import plot_partial_dependence\n",
    "import matplotlib.pyplot as plt\n",
    "from lime import lime_tabular\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "# 1. Feature Importance Analysis (for Random Forest and XGBoost models)\n",
    "# Random Forest Feature Importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Random Forest Feature Importance\")\n",
    "feat_importances_rf = pd.Series(random_forest_model.feature_importances_, index=X_train.columns)\n",
    "feat_importances_rf.nlargest(10).plot(kind='barh')\n",
    "plt.show()\n",
    "\n",
    "# XGBoost Feature Importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"XGBoost Feature Importance\")\n",
    "feat_importances_xgb = pd.Series(xgboost_model.feature_importances_, index=X_train.columns)\n",
    "feat_importances_xgb.nlargest(10).plot(kind='barh')\n",
    "plt.show()\n",
    "\n",
    "# 2. SHAP (SHapley Additive exPlanations)\n",
    "# SHAP Summary Plot for Random Forest\n",
    "explainer_rf = shap.TreeExplainer(random_forest_model)\n",
    "shap_values_rf = explainer_rf.shap_values(X_val)\n",
    "shap.summary_plot(shap_values_rf, X_val, plot_type=\"bar\")\n",
    "\n",
    "# SHAP Summary Plot for XGBoost\n",
    "explainer_xgb = shap.TreeExplainer(xgboost_model)\n",
    "shap_values_xgb = explainer_xgb.shap_values(X_val)\n",
    "shap.summary_plot(shap_values_xgb, X_val, plot_type=\"bar\")\n",
    "\n",
    "# 3. LIME (Local Interpretable Model-agnostic Explanations)\n",
    "# Initialize LIME Explainer\n",
    "lime_explainer = LimeTabularExplainer(X_train.values, mode=\"classification\", feature_names=X_train.columns)\n",
    "\n",
    "# Explain individual predictions using LIME\n",
    "# Example: Explain the first instance in the validation data for the Random Forest model\n",
    "lime_exp_rf = lime_explainer.explain_instance(X_val.iloc[0], random_forest_model.predict_proba, num_features=5)\n",
    "lime_exp_rf.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bc1c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test data\n",
    "y_pred_lr = logistic_regression_model.predict(X_test)\n",
    "y_pred_rf = random_forest_model.predict(X_test)\n",
    "y_pred_xgb = xgboost_model.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "def evaluate_performance(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "print(\"Logistic Regression Model:\")\n",
    "evaluate_performance(y_test, y_pred_lr)\n",
    "print()\n",
    "\n",
    "print(\"Random Forest Model:\")\n",
    "evaluate_performance(y_test, y_pred_rf)\n",
    "print()\n",
    "\n",
    "print(\"XGBoost Model:\")\n",
    "evaluate_performance(y_test, y_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59f537f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
